{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redisai\n",
    "import ml2rt\n",
    "\n",
    "t.model = torchvision.models.resnet50(pretrained=True)\n",
    "t.img_t = torch.rand(1, 3, 224, 224)\n",
    "t.model.eval()\n",
    "t.nn_script = torch.jit.trace(t.model, t.img_t)\n",
    "ml2rt.save_torch(t.nn_script, \"model.pt\")\n",
    "t.loaded_script = ml2rt.load_model('model.pt')\n",
    "t.redis = redisai.Client()\n",
    "t.redis.modelset(\n",
    "    'resnet', \n",
    "    redisai.Backend.torch,\n",
    "    redisai.Device.cpu,\n",
    "    t.loaded_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loop (to run in Gear?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import io, urllib.request, time\n",
    "import os\n",
    "import PIL\n",
    "import torch.nn.functional as F\n",
    "import redisai\n",
    "import ast, requests \n",
    "\n",
    "class Object(object): pass\n",
    "\n",
    "t = Object()\n",
    "\n",
    "t.labels = ast.literal_eval(\n",
    "    requests.get('https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt').text\n",
    ")\n",
    "\n",
    "def softmax(p):\n",
    "    t = np.exp(p)\n",
    "    s = t.sum()\n",
    "    return t / s\n",
    "\n",
    "def get_top_5(preds):\n",
    "    preds = preds.copy()\n",
    "    result = np.zeros(5).astype(np.int32)\n",
    "    for i in range(result.shape[0]):\n",
    "        max_ind = preds.argmax()\n",
    "        result[i] = int(max_ind)\n",
    "        preds[max_ind] = -1\n",
    "    return result\n",
    "\n",
    "def resize_tensor(img):\n",
    "    mean = torch.Tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.Tensor([0.229, .224, .225])\n",
    "    img = img.permute(0, 3, 1, 2)\n",
    "    img /= 255.0\n",
    "    img = F.interpolate(img, size=(224, 224))        \n",
    "    img[0] = img[0].sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "t.api = twitter.Api(\n",
    "    consumer_key=os.environ['TWITTER_CONSUMER_KEY'],\n",
    "    consumer_secret=os.environ['TWITTER_CONSUMER_SECRET'],\n",
    "    access_token_key=os.environ['TWITTER_TOKEN_KEY'],\n",
    "    access_token_secret=os.environ['TWITTER_TOKEN_SECRET'])\n",
    "\n",
    "t.t = t.api.GetUserTimeline(screen_name=\"alexonsoftware\", \n",
    "                        count=10, \n",
    "                        include_rts=False,\n",
    "                        exclude_replies=True)\n",
    "\n",
    "t.since_id = t.t[0].id - 1\n",
    "\n",
    "msg = Object()\n",
    "msg.running = True\n",
    "\n",
    "t.redis = redisai.Client()\n",
    "\n",
    "while msg.running:\n",
    "    msg.t = t.api.GetUserTimeline(screen_name=\"alexonsoftware\", \n",
    "                        count=10, \n",
    "                        include_rts=False,\n",
    "                        exclude_replies=True,\n",
    "                        since_id=t.since_id)\n",
    "    if len(msg.t) > 0:\n",
    "        for msg.tweet in msg.t:\n",
    "            if 'media' in msg.tweet.AsDict():\n",
    "                msg.media_list = msg.tweet.AsDict()['media']\n",
    "                for msg.pic in msg.media_list:\n",
    "                    msg.img = PIL.Image.open(\n",
    "                        io.BytesIO(\n",
    "                            urllib.request.urlopen(\n",
    "                                msg.pic['media_url']).read())).convert('RGB')\n",
    "                    msg.img_t = torch.Tensor(\n",
    "                            np.array(msg.img)).unsqueeze(0).float()\n",
    "                    msg.img_t = resize_tensor(msg.img_t)\n",
    "                    t.redis.tensorset('image', msg.img_t.numpy())\n",
    "                    t.redis.modelrun('resnet', 'image', 'pred')\n",
    "                    \n",
    "                    msg.pred = t.redis.tensorget('pred')[0]\n",
    "                    \n",
    "                    msg.pred = softmax(msg.pred)\n",
    "\n",
    "                    msg.ind = get_top_5(msg.pred)\n",
    "                    \n",
    "                    result = ''\n",
    "                    for msg.p in msg.ind:\n",
    "                        result += f\"{t.labels[msg.p]} : {msg.pred[msg.p]}\\n\"\n",
    "                    print(result)\n",
    "                    t.api.PostUpdate(\n",
    "                        status=result,\n",
    "                        in_reply_to_status_id=msg.tweet.id\n",
    "                    )\n",
    "            t.since_id = max(t.since_id, msg.tweet.id)\n",
    "    time.sleep(1)\n",
    "    msg.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class Recognizer():\n",
    "    def __init__(self):\n",
    "        self.labels = ast.literal_eval(\n",
    "            requests.get('https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt').text\n",
    "        )\n",
    "    \n",
    "    def softmax(self, p):\n",
    "        t = np.exp(p)\n",
    "        s = t.sum()\n",
    "        return t / s\n",
    "    \n",
    "    def predict(self, img):\n",
    "        \n",
    "\n",
    "    def get_top_5(self, preds):\n",
    "        preds = preds.copy()\n",
    "        result = np.zeros(5).astype(np.int32)\n",
    "        for i in range(result.shape[0]):\n",
    "            max_ind = preds.argmax()\n",
    "            result[i] = int(max_ind)\n",
    "            preds[max_ind] = -1\n",
    "        return result\n",
    "\n",
    "    def resize_tensor(img):\n",
    "        mean = torch.Tensor([0.485, 0.456, 0.406])\n",
    "        std = torch.Tensor([0.229, .224, .225])\n",
    "        img = img.permute(0, 3, 1, 2)\n",
    "        img /= 255.0\n",
    "        img = F.interpolate(img, size=(224, 224))        \n",
    "        img[0] = img[0].sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "        return img\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
